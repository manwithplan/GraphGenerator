{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('ref_n', default='', force = True)\n",
    "Token.set_extension('ref_t', default='', force = True)\n",
    "\n",
    "#nlp = spacy.load(\"../NER/models/ner_v1.0\")\n",
    "#nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../stored_data/docs.obj\",'rb')\n",
    "docs = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aubin\\anaconda3\\envs\\nlp-new\\lib\\site-packages\\spacy\\util.py:833: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nlp.get_pipe('ner').labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'_': {'ref_t': {'IN': entities}}}, # subject\n",
    "        {'OP': '*'},\n",
    "        {'_': {'ref_t': {'IN': entities}}}] # object\n",
    "matcher.add(f\"any_verb\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "text = \"Fairchild Corp acquired Fujitsu.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(matches)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = random.sample(list(docs.keys()), 1)\n",
    "random_doc = docs[id[0]]\n",
    "full_doc = \"\"\n",
    "for sent in random_doc:\n",
    "    full_doc += sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for sentence in random_doc:\n",
    "    doc = nlp(sentence)\n",
    "    matches = matcher(doc)\n",
    "    print(matches)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start:end]  # The matched span\n",
    "        print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 HelloWorld 0 3 Hello, world\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [\n",
    "    {\"LOWER\": \"hello\"}, \n",
    "    {\"IS_PUNCT\": True}, \n",
    "    {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", [pattern])\n",
    "\n",
    "doc = nlp(\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "acq_synonyms = ['acquire', 'buy', 'purchase']\n",
    "pattern = [{'_': {'ref_t': 'ORG'}}, # subject\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'OP': '*'},\n",
    "           {'POS': 'VERB', 'LEMMA': {'IN': acq_synonyms}},\n",
    "           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'OP': '*'},\n",
    "           {'_': {'ref_t': 'ORG'}}] # object\n",
    "matcher.add('acquires', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rel_match(doc, matcher):\n",
    "    for sent in doc.sents:\n",
    "        for match_id, start, end in matcher(sent):\n",
    "            span = sent[start:end]  # matched span\n",
    "            pred = nlp.vocab.strings[match_id] # rule name\n",
    "            subj, obj = span[0], span[-1]\n",
    "            if pred.startswith('rev-'): # reversed relation\n",
    "                subj, obj = obj, subj\n",
    "                pred = pred[4:]\n",
    "            yield ((subj._.ref_n, subj._.ref_t), pred, \n",
    "                   (obj._.ref_n, obj._.ref_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Fairchild Corp was acquired by Fujitsu.\"\n",
    "print(*extract_rel_match(nlp(text), matcher), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d77edf4d22c95116f7db69775c20b4e4dae950b1cce7917aaff0b99c27fca43a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp-new': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
